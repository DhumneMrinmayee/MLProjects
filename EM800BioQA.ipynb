{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EM800BioQA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "mount_file_id": "1XWl-HSzlRVpWR79ux01mXkFuHzn8AGgy",
      "authorship_tag": "ABX9TyPUbB8KSEZEQP4HLLUeRfHa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhumneMrinmayee/MLProjects/blob/main/EM800BioQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !nvidia-smi"
      ],
      "metadata": {
        "id": "ockGaEX2_rn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
      ],
      "metadata": {
        "id": "x7tPyg8_VSq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhZvwZON_f_X"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers\n",
        "!pip install  tokenizer\n",
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install pytorch.lightning"
      ],
      "metadata": {
        "id": "-odM4POOYajK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9JSDN-w_oR1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import logging        # logging API \n",
        "import json           #provides a simple command line interface to validate and pretty-print JSON objects\n",
        "import  os\n",
        "import glob          # the glob module is used to retrieve files/pathnames matching a specified pattern\n",
        "import argparse      #Parser for command-line options, arguments and sub-command\n",
        "import textwrap\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split   \n",
        "from string import punctuation        \n",
        "from itertools import chain    #an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable,just like a chain\n",
        "from pathlib import Path     # provides Object-oriented filesystem paths\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from termcolor import colored  # module for ANSII Color formatting for output in the terminal\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n"
      ],
      "metadata": {
        "id": "suwFBCe_GsVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function that sets seed for pseudo-random number generators in: pytorch, numpy, python.random \n",
        "\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "TgMEf0CdYnXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "Sl9v7DmeBUKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('drive/MyDrive/QA.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('drive/MyDrive/train_BioASQ')"
      ],
      "metadata": {
        "id": "_KKxrpT4W58c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Path('drive/MyDrive/train_BioASQ/BioASQ/BioASQ-train-factoid-4b.json').open() as json_file:\n",
        "  data = json.load(json_file)"
      ],
      "metadata": {
        "id": "nt1QsrEFnEZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "id": "oBGwGL2LpWoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['version']"
      ],
      "metadata": {
        "id": "zVbDy5Nxpbsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "Wz-jp7Qspmu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['data'][0].keys()"
      ],
      "metadata": {
        "id": "HTM5hLNrpqUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['data'][0]['title']"
      ],
      "metadata": {
        "id": "637BNhyup7a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['data'][0]['paragraphs'])"
      ],
      "metadata": {
        "id": "DYx_m04EqOHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = data['data'][0]['paragraphs']"
      ],
      "metadata": {
        "id": "pdpj7TI4qr82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries[1]"
      ],
      "metadata": {
        "id": "00Ure95Dq0R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_question_and_answers(factoid_path: Path):\n",
        "  with factoid_path.open() as json_file:\n",
        "    data = json.load(json_file)\n",
        " \n",
        "  queries = data['data'][0]['paragraphs']  \n",
        "  data_rows =[]\n",
        "  for rows in queries:\n",
        "    context = rows['context']\n",
        "    for QA in rows['qas']:\n",
        "      questions = QA['question']\n",
        "      answers = QA['answers']\n",
        "      for answers in answers:\n",
        "        ans_text = answers['text']\n",
        "        ans_start = answers['answer_start']\n",
        "        ans_end= ans_start +len(ans_text)\n",
        "\n",
        "        data_rows.append({\n",
        "            'question':questions,\n",
        "            'context' : context,\n",
        "            'answer_text': ans_text,\n",
        "            'answer_start': ans_start,\n",
        "            'answer_end':ans_end\n",
        "        })\n",
        "    \n",
        "  return pd.DataFrame(data_rows)\n"
      ],
      "metadata": {
        "id": "p6WZMriWrhvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_question_and_answers(Path('drive/MyDrive/train_BioASQ/BioASQ/BioASQ-train-factoid-4b.json')).head()"
      ],
      "metadata": {
        "id": "ucihTEwO4b2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factoid_path = sorted(list(Path('drive/MyDrive/train_BioASQ/BioASQ/').glob('BioASQ-train-*')))\n",
        "factoid_path"
      ],
      "metadata": {
        "id": "BIcRfz2W5ith"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract data into dataframes and combine all train files\n",
        "\n",
        "dataframe = []\n",
        "for factoid_path in factoid_path:\n",
        "  dataframe.append(extract_question_and_answers(factoid_path))\n",
        "\n",
        "#concatinate all the dataframes\n",
        "df = pd.concat(dataframe)"
      ],
      "metadata": {
        "id": "RBxwvz0Z6q6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "-9W4tVH-7t7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "mJ22VupW70Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.drop_duplicates(subset= ['context']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "r9nldWk5KkPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "2kjwBldhK8Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.question.unique())"
      ],
      "metadata": {
        "id": "YfgBSawX80U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.context.unique())"
      ],
      "metadata": {
        "id": "DoS8mG9S9bxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_question = df.iloc[100]\n",
        "sample_question"
      ],
      "metadata": {
        "id": "UpAOFwlM90qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def highlight_ans(question):\n",
        "  answer_start, answer_end = question['answer_start'],question['answer_end']\n",
        "  context= question['context']\n",
        "\n",
        "  return colored(context[:answer_start],\"white\")+\\\n",
        "  colored(context[answer_start:answer_end + 1], \"yellow\")+\\\n",
        "  colored(context[answer_end+ 1:],\"white\")\n"
      ],
      "metadata": {
        "id": "THjdh2tn_vhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_question[\"question\"])\n",
        "print(\"/n\")\n",
        "print(\"Answer:\" )\n",
        "for wrap in textwrap.wrap(highlight_ans(sample_question), width = 100):\n",
        "  print(wrap)"
      ],
      "metadata": {
        "id": "4r-esS35B5BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "\n",
        "model = 't5-base'\n"
      ],
      "metadata": {
        "id": "8OpyaaU5FBaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "id": "A7HPhnZNp3mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_sample = tokenizer(\n",
        "    \"what is your preferred public transport?\",\n",
        "    \"Mostly subway. Also it depends on what time of the day I have to travel.\" \n",
        ")"
      ],
      "metadata": {
        "id": "j2pKJjyKsZnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_sample.keys() "
      ],
      "metadata": {
        "id": "oRHvn-2EtMK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoding_sample['input_ids'])    # input id for each task"
      ],
      "metadata": {
        "id": "PSHt7uS8tSwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoding_sample['attention_mask']) "
      ],
      "metadata": {
        "id": "jhOc1MkVtcE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p =[\n",
        "    tokenizer.decode(input_id,skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    for input_id in encoding_sample['input_ids']\n",
        "]\n"
      ],
      "metadata": {
        "id": "ZB5Uag7dxBqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(p)"
      ],
      "metadata": {
        "id": "9-p0d-5EyXcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_question = tokenizer(\n",
        "    sample_question[\"question\"],\n",
        "    sample_question['context'],\n",
        "    max_length = 1000,\n",
        "    padding= \"max_length\",\n",
        "    truncation = True,\n",
        "    return_attention_mask =True,\n",
        "    add_special_tokens = True,\n",
        "    return_tensors = 'pt'\n",
        ")"
      ],
      "metadata": {
        "id": "41yFSMyM0g0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_question.keys()"
      ],
      "metadata": {
        "id": "v7YkWLxP3k6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#understand the types of special tokens \n",
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "z4NkTnlm3vFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoding_question['input_ids'].squeeze())"
      ],
      "metadata": {
        "id": "IYF_rP7Y44tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_answer = tokenizer(\n",
        "    sample_question[\"answer_text\"],\n",
        "    max_length = 100,\n",
        "    padding= \"max_length\",\n",
        "    return_attention_mask =True,\n",
        "    add_special_tokens = True,\n",
        "    return_tensors = 'pt'\n",
        ")"
      ],
      "metadata": {
        "id": "Ln5Vin5XBZz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoding_answer['input_ids'].squeeze())"
      ],
      "metadata": {
        "id": "uZ7oKbvLCBK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = encoding_answer['input_ids']\n",
        "labels"
      ],
      "metadata": {
        "id": "6OYUsrGOF9bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BioASQDataset(Dataset):\n",
        "\n",
        "  def __init__(\n",
        "      self,                           # self is the first parameter of methods that represents the instance of the class. Therefore, in order to call attributes and methods of a class we use self word\n",
        "      data : pd.DataFrame,\n",
        "      tokenizer: T5Tokenizer,\n",
        "      source_max_token_len: int= 400,\n",
        "      target_max_token_len: int = 70\n",
        "\n",
        "  ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_max_token_len = source_max_token_len\n",
        "    self.target_max_token_len = target_max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "      rows = self.data.iloc[index]\n",
        "\n",
        "      encoding_scource = tokenizer(\n",
        "        rows[\"question\"],\n",
        "        rows['context'],\n",
        "        max_length = self.source_max_token_len,\n",
        "        padding= \"max_length\",\n",
        "        truncation = True,\n",
        "        return_attention_mask =True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = 'pt'\n",
        "      )\n",
        "\n",
        "      encoding_target =tokenizer(\n",
        "        rows[\"answer_text\"],\n",
        "        max_length = self.target_max_token_len,\n",
        "        padding= \"max_length\",\n",
        "        return_attention_mask =True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = 'pt'\n",
        "      )\n",
        "      labels = encoding_target['input_ids']\n",
        "      labels[labels == 0]= -100\n",
        "\n",
        "\n",
        "      return dict(\n",
        "          question = rows['question'],\n",
        "          context = rows['context'],\n",
        "          answer_text = rows['answer_text'],\n",
        "          input_ids = encoding_scource['input_ids'].flatten(),                 # .flatten() Return a copy of the array collapsed into one dimension\n",
        "          attention_mask= encoding_scource['attention_mask'].flatten(),\n",
        "          labels = labels.flatten()\n",
        "      )"
      ],
      "metadata": {
        "id": "9HcuZbCbgilh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = BioASQDataset(df, tokenizer)\n"
      ],
      "metadata": {
        "id": "EN4hhWscgiLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in sample_data:\n",
        "  print(data['question'])\n",
        "  print(data['answer_text'])\n",
        "  print(data['input_ids'][:20])\n",
        "  print(data['labels'][:20])\n",
        "  break"
      ],
      "metadata": {
        "id": "lifglnegq7Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_test_split(df, test_size= 0.10)   #test size default\n",
        "df_train.shape"
      ],
      "metadata": {
        "id": "NX-fmUyuthZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.shape"
      ],
      "metadata": {
        "id": "ExfywIQXukTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Whitening or Sphering is a data pre-processing step. \n",
        "#It can be used to remove correlation or dependencies between features in a dataset. \n",
        "#This may help to better train a machine learning model."
      ],
      "metadata": {
        "id": "YKz3xZXzuzYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a whitening data module to create the training, validation, test sets\n",
        "# Using super() for building a class that extend the functionality of previously built classes.\n",
        "class BioASQDatamodule(pl.LightningDataModule):\n",
        "  def __init__(\n",
        "    self,\n",
        "    df_train: pd.DataFrame,\n",
        "    df_test: pd.DataFrame,\n",
        "    tokenizer: T5Tokenizer,\n",
        "    batch_size : int = 16,\n",
        "    source_max_token_len: int= 400,\n",
        "    target_max_token_len: int = 70\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.df_train =  df_train\n",
        "    self.df_test =  df_test\n",
        "    self.batch_size =  batch_size\n",
        "    self.tokenizer = tokenizer\n",
        "    self.source_max_token_len = source_max_token_len\n",
        "    self.target_max_token_len = target_max_token_len\n",
        "\n",
        "  def frame(self):\n",
        "    self.train_dataset = BioASQDataset(\n",
        "        self.df_train,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_len,\n",
        "        self.target_max_token_len\n",
        "    )\n",
        "\n",
        "    self.test_data = BioASQDataset(\n",
        "        self.df_test,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_len,\n",
        "        self.target_max_token_len\n",
        "    )\n",
        " \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size = self.batch_size,\n",
        "        shuffle = True,\n",
        "        num_workers =4 \n",
        "    )\n",
        "  \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_data,\n",
        "        batch_size = 1,\n",
        "        num_workers =4 \n",
        "    )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_data,\n",
        "        batch_size = 1,\n",
        "        num_workers =4 \n",
        "    )\n",
        "                     "
      ],
      "metadata": {
        "id": "vNa9ayR_o9ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 8\n",
        "N_Epochs =6\n",
        "DataModule = BioASQDatamodule(df_train, df_val, tokenizer, batch_size= Batch_size)\n",
        "\n",
        "\n",
        "DataModule.frame()"
      ],
      "metadata": {
        "id": "u6MknMpwo9OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0vfYACTW9rd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}